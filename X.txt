import os
import pandas as pd
import chromadb
from sentence_transformers import SentenceTransformer

# Initialize ChromaDB and the embedding model
db = chromadb.Client()
model = SentenceTransformer("all-MiniLM-L6-v2")

# Directory containing template CSV files
TEMPLATE_DIR = "path/to/your/templates"

def read_and_chunk_csv(file_path):
    """Reads a CSV file and chunks it by pairing parameters with values."""
    chunks = []
    file_name = os.path.basename(file_path)

    # Read the CSV assuming structured rows (section, parameters, values)
    df = pd.read_csv(file_path, header=None)
    
    for i in range(0, len(df), 3):  # Assuming 3 rows per template section
        section_name = df.iloc[i, 0].strip()
        parameters = df.iloc[i + 1].dropna().tolist()
        values = df.iloc[i + 2].dropna().tolist()

        # Pair parameters with values
        for param, value in zip(parameters, values):
            chunk_text = f"{param}: {value}"
            chunks.append({
                "text": chunk_text,
                "section": section_name,
                "document_id": file_name,
                "parameter": param,
                "value": value
            })
    
    return chunks

def store_chunks(chunks):
    """Generate embeddings and store chunks in ChromaDB."""
    for chunk in chunks:
        text = chunk["text"]
        embedding = model.encode(text).tolist()
        metadata = {
            "document_id": chunk["document_id"],
            "section": chunk["section"],
            "parameter": chunk["parameter"],
            "value": chunk["value"]
        }
        db.add_document(content=text, embedding=embedding, metadata=metadata)

# Process all templates in the directory
for file_name in os.listdir(TEMPLATE_DIR):
    if file_name.endswith(".csv"):
        file_path = os.path.join(TEMPLATE_DIR, file_name)
        chunks = read_and_chunk_csv(file_path)
        store_chunks(chunks)

def process_query(query):
    """Preprocesses the query into searchable terms."""
    return [term.strip().lower() for term in query.split(",") if term.strip()]

def search_chunks(query_terms):
    """Searches ChromaDB for matching chunks."""
    results = []
    for term in query_terms:
        query_embedding = model.encode(term).tolist()
        matches = db.query(query_embedding, n_results=5)
        results.extend(matches)

    grouped_results = {}
    for match in results:
        doc_id = match.metadata["document_id"]
        grouped_results.setdefault(doc_id, []).append(match)
    
    return grouped_results

def retrieve_full_templates(matched_docs):
    """Display full templates for matched documents."""
    for doc_id in matched_docs.keys():
        file_path = os.path.join(TEMPLATE_DIR, doc_id)
        print(f"\nMatching Template from: {doc_id}")
        with open(file_path, "r") as f:
            print(f.read())

# Example query
query = "conf, kil"
query_terms = process_query(query)
matched_docs = search_chunks(query_terms)

# Retrieve and display matching full templates
retrieve_full_templates(matched_docs)
